{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 스미싱 문자 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 전처리\n",
    "### 사용자 단위 전처리\n",
    "> 공백 비율, 평균 문자 시간 간격, 평균 문장 길이, 문장 내 욕설 비율, 문장 내 오타 비율, 문장 내 말줄임 비율 등이 있다.\n",
    "\n",
    "- 금융 문자이므로 제외\n",
    "\n",
    "### 대화 세션 단위 전처리\n",
    "- 대화가 아니므로 제외\n",
    "\n",
    "### 문장 단위 전처리\n",
    "한글의 경우 맞춤법이 틀리고 띄어쓰기가 제대로 지켜지지 않는다.  \n",
    "그러나 훈련과정이 어렵고 오래걸린다.\n",
    "\n",
    "### 정규화\n",
    "#### 걸러내기\n",
    "Filtering은 불량한 데이터를 지우는 것이다. (불량한 데이터 없음)\n",
    "#### 풀어쓰기\n",
    "바꾸기(Replacing) 혹은 풀어쓰기(Paraphrasing)는 같은 의미를 갖지만 서로 다른 표현으로 나타내는 말들을 하나로 통일시켜 주는 작업니다.\n",
    "* 숫자: 아라비아 수와 기수, 한자 표현 중 택\n",
    "* 이모티콘, 특수문자 -> 없음\n",
    "* URL: [URL]로 대체\n",
    "* 영어: 명칭이 현재 XXX로, 추첨(?)코드에 영문 포함\n",
    "\n",
    "### 띄어쓰기 교정\n",
    "한국어 띄어쓰기 교정 모델: KoSpacing, RAWS, pingpong-ai/chatspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenizng\n",
    "**단어 토큰화**\n",
    "형태소 분석기: Mecab, Otk, Khaii, SentencePeice(BPE 기반)\n",
    "\n",
    "형태소 분석기 - 사용자 사전 추가(ex. 카카오톡, 코드)\n",
    "\n",
    "**문장 토큰화**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Word Embedding\n",
    "\n",
    "### Frequency based Embedding\n",
    "BOW(Bag of words)  \n",
    "단어들의 출현 빈도에만 집중하는 방법  \n",
    "이에 해당하는 방법 중 하나  \n",
    "* Count Vector(Base-Line 코드에서 사용)  \n",
    "\n",
    "TF-IDF(Term Frequency - Inverse Document Frequency) Vector  \n",
    "단어 빈도 - 역 문서 빈도  \n",
    "tf(d,t) : 특정 문서 d에서 특정 단어 t의 등장 횟수  \n",
    "df(t) : 특정 단어 t가 등장한 문서의 수  \n",
    "idf(d,t) : df(t)에 반비례하는 수\n",
    "> 단, 총 문서의 수가 많아지는 경우를 우려해 log를 취한다.\n",
    "특정 단어가 문서들에서 등장하지 않는 경우 분모가 0이 되는 것을 1을 더해 방지한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction based Vector\n",
    "진정한 의미의 워드 임베딩으로 단어의 의미를 벡터화 하는 작업을 말한다.\n",
    "\n",
    "word2vec  \n",
    "\n",
    "CBOW(Contitnuous Bag of words)  \n",
    "주변에 있는 단어들을 가지고, 중간에 있는 단어들을 예측하는 방법이다.\n",
    "\n",
    "중심 단어를 예측하기 위해 앞, 뒤로 몇 개의 단어를 볼지 결정한 범위 - window\n",
    "중심 단어를 예측하기 위해 참고하는 주변 단어의 수는 2n\n",
    "\n",
    "Skip-gram  \n",
    "중간에 있는 단어로 주변 단어들을 예측하는 방법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
